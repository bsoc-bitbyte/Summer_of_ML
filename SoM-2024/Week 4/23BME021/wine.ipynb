{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on Wine Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ayushsaksena/Desktop/Interests/SOM/datasets/wine+quality/winequality-red.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking to see any NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           False\n",
       "volatile acidity        False\n",
       "citric acid             False\n",
       "residual sugar          False\n",
       "chlorides               False\n",
       "free sulfur dioxide     False\n",
       "total sulfur dioxide    False\n",
       "density                 False\n",
       "pH                      False\n",
       "sulphates               False\n",
       "alcohol                 False\n",
       "quality                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Dataset as X and Y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['quality'],axis='columns')\n",
    "Y = df.quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Dataset\n",
    "\n",
    "For this We can use:\n",
    "1) Seaborn\n",
    "2) MatplotLib\n",
    "\n",
    "We'll be using Matplotlib library to plot and see the database to decide which columns to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x173c01340>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(df['alcohol'],df.quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best model and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As taught in Week 4, We'll be using GridSearchCV to find the best hyperparameter for the model. It is because the dataset is small so searching through all the parameters will be the best and not take a lot of time.\n",
    "\n",
    "As this is Classification after looking at the graph, We'll be testing on the following 4 models:\n",
    "1) Logistic Regression\n",
    "2) Decision Tree Classifier\n",
    "3) Random Forest Classifier\n",
    "4) KNN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5841222570532916"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(LogisticRegression(multi_class='multinomial',max_iter=400),\n",
    "            {'C': [1,5,10]}, cv=5)\n",
    "\n",
    "clf.fit(X, Y)\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070210</td>\n",
       "      <td>0.018365</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.583072</td>\n",
       "      <td>0.574114</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054758</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.603125</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.592476</td>\n",
       "      <td>0.579120</td>\n",
       "      <td>0.027726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055033</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.528125</td>\n",
       "      <td>0.571875</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.595611</td>\n",
       "      <td>0.584122</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.070210      0.018365         0.000842        0.000510       1   \n",
       "1       0.054758      0.000957         0.000496        0.000066       5   \n",
       "2       0.055033      0.000299         0.000445        0.000060      10   \n",
       "\n",
       "      params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'C': 1}           0.521875           0.562500           0.609375   \n",
       "1   {'C': 5}           0.525000           0.584375           0.603125   \n",
       "2  {'C': 10}           0.528125           0.571875           0.625000   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.593750           0.583072         0.574114        0.030242   \n",
       "1           0.590625           0.592476         0.579120        0.027726   \n",
       "2           0.600000           0.595611         0.584122        0.032683   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                2  \n",
       "2                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5246845611285267"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df[['alcohol']]\n",
    "clf = GridSearchCV(tree.DecisionTreeClassifier(),{\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random']\n",
    "}, cv=5)\n",
    "clf.fit(X_train, Y)\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'splitter': 'random'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'splitter': 'best'}</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.503125</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.489028</td>\n",
       "      <td>0.523431</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'splitter': 'random'}</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.503125</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.492163</td>\n",
       "      <td>0.524058</td>\n",
       "      <td>0.033218</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'splitter': 'best'}</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.503125</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.489028</td>\n",
       "      <td>0.523431</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'splitter': 'random'}</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.503125</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.495298</td>\n",
       "      <td>0.524685</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'splitter': 'best'}</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.503125</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.489028</td>\n",
       "      <td>0.523431</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'splitter': 'random'}</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.503125</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.495298</td>\n",
       "      <td>0.524685</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.000837      0.000307         0.000405        0.000036   \n",
       "1       0.000744      0.000246         0.000501        0.000254   \n",
       "2       0.000814      0.000168         0.000425        0.000064   \n",
       "3       0.000606      0.000052         0.000374        0.000033   \n",
       "4       0.000630      0.000014         0.000363        0.000004   \n",
       "5       0.000626      0.000052         0.000396        0.000073   \n",
       "\n",
       "  param_criterion param_splitter  \\\n",
       "0            gini           best   \n",
       "1            gini         random   \n",
       "2         entropy           best   \n",
       "3         entropy         random   \n",
       "4        log_loss           best   \n",
       "5        log_loss         random   \n",
       "\n",
       "                                            params  split0_test_score  \\\n",
       "0        {'criterion': 'gini', 'splitter': 'best'}            0.50625   \n",
       "1      {'criterion': 'gini', 'splitter': 'random'}            0.50625   \n",
       "2     {'criterion': 'entropy', 'splitter': 'best'}            0.50625   \n",
       "3   {'criterion': 'entropy', 'splitter': 'random'}            0.50625   \n",
       "4    {'criterion': 'log_loss', 'splitter': 'best'}            0.50625   \n",
       "5  {'criterion': 'log_loss', 'splitter': 'random'}            0.50625   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.503125           0.584375           0.534375           0.489028   \n",
       "1           0.503125           0.584375           0.534375           0.492163   \n",
       "2           0.503125           0.584375           0.534375           0.489028   \n",
       "3           0.503125           0.584375           0.534375           0.495298   \n",
       "4           0.503125           0.584375           0.534375           0.489028   \n",
       "5           0.503125           0.584375           0.534375           0.495298   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.523431        0.033838                4  \n",
       "1         0.524058        0.033218                3  \n",
       "2         0.523431        0.033838                4  \n",
       "3         0.524685        0.032635                1  \n",
       "4         0.523431        0.033838                4  \n",
       "5         0.524685        0.032635                1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575362460815047"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(),{\n",
    "     'criterion': ['gini', 'entropy', 'log_loss']\n",
    "}, cv=5)\n",
    "clf.fit(X, Y)\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.152999</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.540625</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.579937</td>\n",
       "      <td>0.575362</td>\n",
       "      <td>0.024021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.186388</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.598746</td>\n",
       "      <td>0.572874</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185496</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'criterion': 'log_loss'}</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.553125</td>\n",
       "      <td>0.628125</td>\n",
       "      <td>0.571875</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.569116</td>\n",
       "      <td>0.039974</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.152999      0.000869         0.004111        0.000216   \n",
       "1       0.186388      0.002003         0.004021        0.000158   \n",
       "2       0.185496      0.001742         0.003926        0.000119   \n",
       "\n",
       "  param_criterion                     params  split0_test_score  \\\n",
       "0            gini      {'criterion': 'gini'}           0.540625   \n",
       "1         entropy   {'criterion': 'entropy'}           0.543750   \n",
       "2        log_loss  {'criterion': 'log_loss'}           0.506250   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.556250           0.606250           0.593750           0.579937   \n",
       "1           0.543750           0.600000           0.578125           0.598746   \n",
       "2           0.553125           0.628125           0.571875           0.586207   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.575362        0.024021                1  \n",
       "1         0.572874        0.025017                2  \n",
       "2         0.569116        0.039974                3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using KNN Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5015458463949842"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, Y)\n",
    "grid_search.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
